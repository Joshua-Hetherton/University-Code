{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARNING\n",
    "\n",
    "This notebook serves as supporting material for topics covered in **Chapter 18 - Learning from Examples** , **Chapter 19 - Knowledge in Learning**, **Chapter 20 - Learning Probabilistic Models** from the book *Artificial Intelligence: A Modern Approach*. This notebook uses implementations from [learning.py](https://github.com/aimacode/aima-python/blob/master/learning.py). Let's start by importing everything from the module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from learning import *\n",
    "from notebook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. CONTENTS\n",
    "\n",
    "* Machine Learning Overview\n",
    "* Datasets\n",
    "* Iris Visualization\n",
    "* Distance Functions\n",
    "* k-Nearest Neighbours\n",
    "* Decision Tree Learner\n",
    "* Linear Learner\n",
    "* Logistic Linear Learner\n",
    "* Model Evaluation & Comparison\n",
    "* Hands-on Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MACHINE LEARNING OVERVIEW\n",
    "\n",
    "In this notebook, we learn about agents that can improve their behavior through diligent study of their own experiences.\n",
    "\n",
    "An agent is **learning** if it improves its performance on future tasks after making observations about the world.\n",
    "\n",
    "There are three types of feedback that determine the three main types of learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Supervised Learning**:\n",
    "\n",
    "In Supervised Learning the agent observes some example input-output pairs and learns a function that maps from input to output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Let's think of an agent to classify images containing cats or dogs. If we provide an image containing a cat or a dog, this agent should output a string \"cat\" or \"dog\" for that particular image. To teach this agent, we will give a lot of input-output pairs like {cat image-\"cat\"}, {dog image-\"dog\"} to the agent. The agent then learns a function that maps from an input image to one of those strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Unsupervised Learning**:\n",
    "\n",
    "In Unsupervised Learning the agent learns patterns in the input even though no explicit feedback is supplied. The most common type is **clustering**: detecting potential useful clusters of input examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: A taxi agent would develop a concept of *good traffic days* and *bad traffic days* without ever being given labeled examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reinforcement Learning**:\n",
    "\n",
    "In Reinforcement Learning the agent learns from a series of reinforcementsâ€”rewards or punishments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Let's talk about an agent to play the popular Atari gameâ€”[Pong](http://www.ponggame.org). We will reward a point for every correct move and deduct a point for every wrong move from the agent. Eventually, the agent will figure out its actions prior to reinforcement were most responsible for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DATASETS\n",
    "\n",
    "For the following tutorials we will use a range of datasets, to better showcase the strengths and weaknesses of the algorithms. The datasests are the following:\n",
    "\n",
    "* [Fisher's Iris](https://github.com/aimacode/aima-data/blob/a21fc108f52ad551344e947b0eb97df82f8d2b2b/iris.csv): Each item represents a flower, with four measurements: the length and the width of the sepals and petals. Each item/flower is categorized into one of three species: Setosa, Versicolor and Virginica.\n",
    "\n",
    "* [Zoo](https://github.com/aimacode/aima-data/blob/a21fc108f52ad551344e947b0eb97df82f8d2b2b/zoo.csv): The dataset holds different animals and their classification as \"mammal\", \"fish\", etc. The new animal we want to classify has the following measurements: 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 4, 1, 0, 1 (don't concern yourself with what the measurements mean)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make using the datasets easier, we have written a class, `DataSet`, in `learning.py`. The tutorials found here make use of this class.\n",
    "\n",
    "Let's have a look at how it works before we get started with the algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Intro\n",
    "\n",
    "A lot of the datasets we will work with are .csv files (although other formats are supported too). We have a collection of sample datasets ready to use [on aima-data](https://github.com/aimacode/aima-data/tree/a21fc108f52ad551344e947b0eb97df82f8d2b2b). Two examples are the datasets mentioned above (*iris.csv* and *zoo.csv*). You can find plenty datasets online, and a good repository of such datasets is [UCI Machine Learning Repository](https://archive.ics.uci.edu/). Other notable platforms are [OpenML](https://www.openml.org/) and [Kaggle](https://www.kaggle.com/).\n",
    "\n",
    "In such files, each line corresponds to one item/measurement. Each individual value in a line represents a *feature* and usually there is a value denoting the *class* of the item.\n",
    "\n",
    "You can find the code for the dataset here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psource(DataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Class Attributes\n",
    "\n",
    "* **examples**: Holds the items of the dataset. Each item is a list of values.\n",
    "* **attrs**: The indexes of the features (by default in the range of [0,f), where *f* is the number of features). For example, `item[i]` returns the feature at index *i* of *item*.\n",
    "* **attr_names**: An optional list with attribute names. For example, `item[s]`, where *s* is a feature name, returns the feature of name *s* in *item*.\n",
    "* **target**: The attribute a learning algorithm will try to predict. By default the last attribute.\n",
    "* **inputs**: This is the list of attributes without the target.\n",
    "* **values**: A list of lists which holds the set of possible values for the corresponding attribute/feature. If initially `None`, it gets computed (by the function `setproblem`) from the examples.\n",
    "* **distance**: The distance function used in the learner to calculate the distance between two items. By default `mean_boolean_error`.\n",
    "* **name**: Name of the dataset.\n",
    "* **source**: The source of the dataset (url or other). Not used in the code.\n",
    "* **exclude**: A list of indexes to exclude from `inputs`. The list can include either attribute indexes (attrs) or names (attr_names)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Class Helper Functions\n",
    "\n",
    "These functions help modify a `DataSet` object to your needs.\n",
    "\n",
    "* **sanitize**: Takes as input an example and returns it with non-input (target) attributes replaced by `None`. Useful for testing. Keep in mind that the example given is not itself sanitized, but instead a sanitized copy is returned.\n",
    "\n",
    "* **classes_to_numbers**: Maps the class names of a dataset to numbers. If the class names are not given, they are computed from the dataset values. Useful for classifiers that return a numerical value instead of a string.\n",
    "\n",
    "* **remove_examples**: Removes examples containing a given value. Useful for removing examples with missing values, or for removing classes (needed for binary classifiers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Importing a Dataset\n",
    "\n",
    "#### Importing from aima-data\n",
    "\n",
    "Datasets uploaded on aima-data can be imported with the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = DataSet(name=\"iris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that we imported the correct dataset, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.examples[0])\n",
    "print(iris.inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which correctly prints the first line in the csv file and the list of attribute indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When importing a dataset, we can specify to exclude an attribute (for example, at index 1) by setting the parameter `exclude` to the attribute index or name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris2 = DataSet(name=\"iris\",exclude=[1])\n",
    "print(iris2.inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Attributes\n",
    "\n",
    "Here we showcase the attributes.\n",
    "\n",
    "First we will print the first three items/examples in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.examples[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will print `attrs`, `attrnames`, `target`, `input`. Notice how `attrs` holds values in [0,4], but since the fourth attribute is the target, `inputs` holds values in [0,3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"attrs:\", iris.attrs)\n",
    "print(\"attr_names (by default same as attrs):\", iris.attr_names)\n",
    "print(\"target:\", iris.target)\n",
    "print(\"inputs:\", iris.inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will print all the possible values for the first feature/attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will print the dataset's name and source. Keep in mind that we have not set a source for the dataset, so in this case it is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"name:\", iris.name)\n",
    "print(\"source:\", iris.source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful combination of the above is `dataset.values[dataset.target]` which returns the possible values of the target. For classification problems, this will return all the possible classes. Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.values[iris.target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now take a look at the auxiliary functions found in the class.\n",
    "\n",
    "First we will take a look at the `sanitize` function, which sets the non-input values of the given example to `None`.\n",
    "\n",
    "In this case we want to hide the class of the first example, so we will sanitize it.\n",
    "\n",
    "Note that the function doesn't actually change the given example; it returns a sanitized *copy* of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sanitized:\",iris.sanitize(iris.examples[0]))\n",
    "print(\"Original:\",iris.examples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the `iris` dataset has three classes, setosa, virginica and versicolor. We want though to convert it to a binary class dataset (a dataset with two classes). The class we want to remove is \"virginica\". To accomplish that we will utilize the helper function `remove_examples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris2 = DataSet(name=\"iris\")\n",
    "\n",
    "iris2.remove_examples(\"virginica\")\n",
    "print(iris2.values[iris2.target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have `classes_to_numbers`. For a lot of the classifiers in the module (like the Neural Network), classes should have numerical values. With this function we map string class names to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class of first example:\",iris2.examples[0][iris2.target])\n",
    "iris2.classes_to_numbers()\n",
    "print(\"Class of first example:\",iris2.examples[0][iris2.target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see \"setosa\" was mapped to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we take a look at `find_means_and_deviations`. It finds the means and standard deviations of the features for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, deviations = iris.find_means_and_deviations()\n",
    "\n",
    "print(\"Setosa feature means:\", means[\"setosa\"])\n",
    "print(\"Versicolor mean for first feature:\", means[\"versicolor\"][0])\n",
    "\n",
    "print(\"Setosa feature deviations:\", deviations[\"setosa\"])\n",
    "print(\"Virginica deviation for second feature:\",deviations[\"virginica\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. IRIS VISUALIZATION\n",
    "\n",
    "Since we will use the iris dataset extensively in this notebook, below we provide a visualization tool that helps in comprehending the dataset and thus how the algorithms work.\n",
    "\n",
    "We plot the dataset in a 3D space using `matplotlib` and the function `show_iris` from `notebook.py`. The function takes as input three parameters, *i*, *j* and *k*, which are indicises to the iris features, \"Sepal Length\", \"Sepal Width\", \"Petal Length\" and \"Petal Width\" (0 to 3). By default we show the first three features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = DataSet(name=\"iris\")\n",
    "\n",
    "show_iris()\n",
    "show_iris(0, 1, 3)\n",
    "show_iris(1, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play around with the values to get a good look at the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DISTANCE FUNCTIONS\n",
    "\n",
    "In a lot of algorithms, there is a need to compare items, finding how *similar* or *close* they are. For that we have many different functions at our disposal. Below are the functions implemented in the module:\n",
    "\n",
    "### 4.1. Manhattan Distance (`manhattan_distance`)\n",
    "\n",
    "One of the simplest distance functions. It calculates the difference between the coordinates/features of two items. To understand how it works, imagine a 2D grid with coordinates *x* and *y*. In that grid we have two items, at the squares positioned at `(1,2)` and `(3,4)`. The difference between their two coordinates is `3-1=2` and `4-2=2`. If we sum these up we get `4`. That means to get from `(1,2)` to `(3,4)` we need four moves; two to the right and two more up. The function works similarly for n-dimensional grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(X, Y):\n",
    "    return sum([abs(x - y) for x, y in zip(X, Y)])\n",
    "\n",
    "\n",
    "distance = manhattan_distance([1,2], [3,4])\n",
    "print(\"Manhattan Distance between (1,2) and (3,4) is\", distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Euclidean Distance (`euclidean_distance`)\n",
    "\n",
    "Probably the most popular distance function. It returns the square root of the sum of the squared differences between individual elements of two items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(X, Y):\n",
    "    return math.sqrt(sum([(x - y)**2 for x, y in zip(X,Y)]))\n",
    "\n",
    "\n",
    "distance = euclidean_distance([1,2], [3,4])\n",
    "print(\"Euclidean Distance between (1,2) and (3,4) is\", distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Hamming Distance (`hamming_distance`)\n",
    "\n",
    "This function counts the number of differences between single elements in two items. For example, if we have two binary strings \"111\" and \"011\" the function will return 1, since the two strings only differ at the first element. The function works the same way for non-binary strings too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(X, Y):\n",
    "    return sum(x != y for x, y in zip(X, Y))\n",
    "\n",
    "\n",
    "distance = hamming_distance(['a','b','c'], ['a','b','b'])\n",
    "print(\"Hamming Distance between 'abc' and 'abb' is\", distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Mean Boolean Error (`mean_boolean_error`)\n",
    "\n",
    "To calculate this distance, we find the ratio of different elements over all elements of two items. For example, if the two items are `(1,2,3)` and `(1,4,5)`, the ration of different/all elements is 2/3, since they differ in two out of three elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_boolean_error(X, Y):\n",
    "    return mean(int(x != y) for x, y in zip(X, Y))\n",
    "\n",
    "\n",
    "distance = mean_boolean_error([1,2,3], [1,4,5])\n",
    "print(\"Mean Boolean Error Distance between (1,2,3) and (1,4,5) is\", distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Mean Error (`mean_error`)\n",
    "\n",
    "This function finds the mean difference of single elements between two items. For example, if the two items are `(1,0,5)` and `(3,10,5)`, their error distance is `(3-1) + (10-0) + (5-5) = 2 + 10 + 0 = 12`. The mean error distance therefore is `12/3=4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_error(X, Y):\n",
    "    return mean([abs(x - y) for x, y in zip(X, Y)])\n",
    "\n",
    "\n",
    "distance = mean_error([1,0,5], [3,10,5])\n",
    "print(\"Mean Error Distance between (1,0,5) and (3,10,5) is\", distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Mean Square Error (`ms_error`)\n",
    "\n",
    "This is very similar to the `Mean Error`, but instead of calculating the difference between elements, we are calculating the *square* of the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms_error(X, Y):\n",
    "    return mean([(x - y)**2 for x, y in zip(X, Y)])\n",
    "\n",
    "\n",
    "distance = ms_error([1,0,5], [3,10,5])\n",
    "print(\"Mean Square Distance between (1,0,5) and (3,10,5) is\", distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7. Root of Mean Square Error (`rms_error`)\n",
    "\n",
    "This is the square root of `Mean Square Error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms_error(X, Y):\n",
    "    return math.sqrt(ms_error(X, Y))\n",
    "\n",
    "\n",
    "distance = rms_error([1,0,5], [3,10,5])\n",
    "print(\"Root of Mean Error Distance between (1,0,5) and (3,10,5) is\", distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. K-NEAREST NEIGHBOURS CLASSIFIER\n",
    "\n",
    "### 5.1. Overview\n",
    "The k-Nearest Neighbors algorithm is a non-parametric method used for classification and regression. We are going to use this to classify Iris flowers. More about kNN on [Scholarpedia](http://www.scholarpedia.org/article/K-nearest_neighbor).\n",
    "\n",
    "![kNN plot](images/knn_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how kNN works with a simple plot shown in the above picture.\n",
    "\n",
    "We have co-ordinates (we call them **features** in Machine Learning) of this red star and we need to predict its class using the kNN algorithm. In this algorithm, the value of **k** is arbitrary. **k** is one of the **hyper parameters** for kNN algorithm. We choose this number based on our dataset and choosing a particular number is known as **hyper parameter tuning/optimising**. We learn more about this in coming topics.\n",
    "\n",
    "Let's put **k = 3**. It means you need to find 3-Nearest Neighbors of this red star and classify this new point into the majority class. Observe that smaller circle which contains three points other than **test point** (red star). As there are two violet points, which form the majority, we predict the class of red star as **violet- Class B**.\n",
    "\n",
    "Similarly if we put **k = 5**, you can observe that there are three yellow points, which form the majority. So, we classify our test point as **yellow- Class A**.\n",
    "\n",
    "In practical tasks, we iterate through a bunch of values for k (like [1, 3, 5, 10, 20, 50, 100]), see how it performs and select the best one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Implementation\n",
    "\n",
    "Below follows the implementation of the kNN algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psource(NearestNeighborLearner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes as input a dataset and k (default value is 1) and it returns a function, which we can later use to classify a new item.\n",
    "\n",
    "To accomplish that, the function uses a heap-queue, where the items of the dataset are sorted according to their distance from *example* (the item to classify). We then take the k smallest elements from the heap-queue and we find the majority class. We classify the item to this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Example\n",
    "\n",
    "We measured a new flower with the following values: 5.1, 3.0, 1.1, 0.1. We want to classify that item/flower in a class. To do that, we write the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = DataSet(name=\"iris\")\n",
    "\n",
    "kNN = NearestNeighborLearner(iris,k=3)\n",
    "print(kNN([5.1,3.0,1.1,0.1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the above code is \"setosa\", which means the flower with the above measurements is of the \"setosa\" species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. DECISION TREE LEARNER\n",
    "\n",
    "### 6.1. Overview\n",
    "\n",
    "#### 6.1.1. Decision Trees\n",
    "A decision tree is a flowchart that uses a tree of decisions and their possible consequences for classification. At each non-leaf node of the tree an attribute of the input is tested, based on which corresponding branch leading to a child-node is selected. At the leaf node the input is classified based on the class label of this leaf node. The paths from root to leaves represent classification rules based on which leaf nodes are assigned class labels.\n",
    "![perceptron](images/decisiontree_fruit.jpg)\n",
    "\n",
    "#### 6.1.2. Decision Tree Learning\n",
    "Decision tree learning is the construction of a decision tree from class-labeled training data. The data is expected to be a tuple in which each record of the tuple is an attribute used for classification. The decision tree is built top-down, by choosing a variable at each step that best splits the set of items. There are different metrics for measuring the \"best split\". These generally measure the homogeneity of the target variable within the subsets.\n",
    "\n",
    "#### 6.1.3. Gini Impurity\n",
    "Gini impurity of a set is the probability of a randomly chosen element to be incorrectly labeled if it was randomly labeled according to the distribution of labels in the set.\n",
    "\n",
    "$$I_G(p) = \\sum{p_i(1 - p_i)} = 1 - \\sum{p_i^2}$$\n",
    "\n",
    "We select a split which minimizes the Gini impurity in child nodes.\n",
    "\n",
    "#### 6.1.4. Information Gain\n",
    "Information gain is based on the concept of entropy from information theory. Entropy is defined as:\n",
    "\n",
    "$$H(p) = -\\sum{p_i \\log_2{p_i}}$$\n",
    "\n",
    "Information Gain is difference between entropy of the parent and weighted sum of entropy of children. The feature used for splitting is the one which provides the most information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Implementation\n",
    "The nodes of the tree constructed by our learning algorithm are stored using either `DecisionFork` or `DecisionLeaf` based on whether they are a parent node or a leaf node respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(DecisionFork)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DecisionFork` holds the attribute, which is tested at that node, and a dict of branches. The branches store the child nodes, one for each of the attribute's values. Calling an object of this class as a function with input tuple as an argument returns the next node in the classification path based on the result of the attribute test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psource(DecisionLeaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The leaf node stores the class label in `result`. All input tuples' classification paths end on a `DecisionLeaf` whose `result` attribute decide their class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psource(DecisionTreeLearner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of `DecisionTreeLearner` provided in [learning.py](https://github.com/aimacode/aima-python/blob/master/learning.py) uses information gain as the metric for selecting which attribute to test for splitting. The function builds the tree top-down in a recursive manner. Based on the input it makes one of the four choices:\n",
    "<ol>\n",
    "<li>If the input at the current step has no training data we return the mode of classes of input data received in the parent step (previous level of recursion).</li>\n",
    "<li>If all values in training data belong to the same class it returns a `DecisionLeaf` whose class label is the class which all the data belongs to.</li>\n",
    "<li>If the data has no attributes that can be tested we return the class with highest plurality value in the training data.</li>\n",
    "<li>We choose the attribute which gives the highest amount of entropy gain and return a `DecisionFork` which splits based on this attribute. Each branch recursively calls `decision_tree_learning` to construct the sub-tree.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Example\n",
    "\n",
    "We will now use the Decision Tree Learner to classify a sample with values: 5.1, 3.0, 1.1, 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = DataSet(name=\"iris\")\n",
    "\n",
    "DTL = DecisionTreeLearner(iris)\n",
    "print(DTL([5.1, 3.0, 1.1, 0.1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the Decision Tree learner classifies the sample as \"setosa\" as seen in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LINEAR LEARNER\n",
    "\n",
    "### 7.1. Overview\n",
    "\n",
    "Linear Learner is a model that assumes a linear relationship between the input variables x and the single output variable y. More specifically, that y can be calculated from a linear combination of the input variables x. Linear learner is a quite simple model as the representation of this model is a linear equation.  \n",
    "\n",
    "The linear equation assigns one scaler factor to each input value or column, called a coefficients or weights. One additional coefficient is also added, giving additional degree of freedom and is often called the intercept or the bias coefficient.   \n",
    "For example :  y = ax1 + bx2 + c .  \n",
    "\n",
    "### 7.2. Implementation\n",
    "\n",
    "Below mentioned is the implementation of Linear Learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(LinearLearner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm first assigns some random weights to the input variables and then based on the error calculated updates the weight for each variable. Finally the prediction is made with the updated weights.  \n",
    "\n",
    "### 7.3. Example\n",
    "\n",
    "We will now use the Linear Learner to classify a sample with values: 5.1, 3.0, 1.1, 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of features: {len(iris.inputs)}\")\n",
    "print(f\"Example shape: {len(iris.examples[0])}\")\n",
    "print(f\"First example: {iris.examples[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = DataSet(name=\"iris\")\n",
    "iris.classes_to_numbers()\n",
    "\n",
    "linear_learner = LinearLearner(iris)\n",
    "print(linear_learner([5, 3, 1, 0.1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. LOGISTIC LINEAR LEARNER\n",
    "\n",
    "### 8.1. Overview\n",
    "\n",
    "While the Linear Learner we just explored is great for regression (predicting continuous values), it's not ideal for classification tasks. The main problem is that linear regression can output any value from negative infinity to positive infinity, but for classification we want outputs between 0 and 1 that we can interpret as probabilities.\n",
    "\n",
    "Logistic Linear Learner solves this by using the sigmoid function to \"squash\" the linear output into the range [0,1]:\n",
    "\n",
    "$$\\text{probability} = \\text{sigmoid}(w_0 + w_1 x_1 + w_2 x_2 + ... + w_n x_n)$$\n",
    "\n",
    "Where the sigmoid function is:\n",
    "$$\\text{sigmoid}(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "### 8.2. Why Use Sigmoid?\n",
    "\n",
    "The sigmoid function has some very useful properties:\n",
    "- Output range: Always between 0 and 1, perfect for probabilities\n",
    "- S-shaped curve: Smooth transition from 0 to 1\n",
    "- Interpretable: Output can be read as \"confidence\" in the prediction\n",
    "\n",
    "Let's visualize the sigmoid function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the sigmoid function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a range of z values\n",
    "z = np.linspace(-10, 10, 100)\n",
    "# Apply sigmoid function: 1 / (1 + e^(-z))\n",
    "sigmoid_values = 1 / (1 + np.exp(-z))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(z, sigmoid_values, 'b-', linewidth=2, label='Sigmoid Function')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlabel('Input (z)', fontsize=12)\n",
    "plt.ylabel('Output (sigmoid(z))', fontsize=12)\n",
    "plt.title('The Sigmoid Function: Converting Any Number to [0,1]', fontsize=14)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='Decision Boundary (0.5)')\n",
    "plt.axvline(x=0, color='g', linestyle='--', alpha=0.7, label='z = 0')\n",
    "plt.legend()\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.show()\n",
    "\n",
    "print(\"Key properties of the sigmoid function:\")\n",
    "print(f\"sigmoid(-10) = {1/(1+np.exp(10)):.6f} â‰ˆ 0\")\n",
    "print(f\"sigmoid(0) = {1/(1+np.exp(0)):.1f}\")  \n",
    "print(f\"sigmoid(10) = {1/(1+np.exp(-10)):.6f} â‰ˆ 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3. Implementation\n",
    "\n",
    "Let's look at the Logistic Linear Learner implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psource(LogisticLinearLearner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4. Example: Binary Classification\n",
    "\n",
    "For this example, we'll create a binary classification problem from the iris dataset by removing one of the classes. This will help us see how logistic regression works with a simpler two-class problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary classification dataset\n",
    "iris_binary = DataSet(name=\"iris\")\n",
    "iris_binary.remove_examples(\"virginica\")  # Remove virginica class\n",
    "iris_binary.classes_to_numbers()  # Convert classes to numbers (setosa=0, versicolor=1)\n",
    "\n",
    "print(\"Binary iris dataset:\")\n",
    "print(f\"Classes: {iris_binary.values[iris_binary.target]}\")\n",
    "print(f\"Number of examples: {len(iris_binary.examples)}\")\n",
    "print(f\"First few examples:\")\n",
    "for i in range(3):\n",
    "    print(f\"  {iris_binary.examples[i]}\")\n",
    "\n",
    "# Train logistic regression\n",
    "logistic_learner = LogisticLinearLearner(iris_binary, learning_rate=0.1, epochs=1000)\n",
    "\n",
    "# Test with the same flower as before\n",
    "test_flower = [5.1, 3.0, 1.1, 0.1]\n",
    "probability = logistic_learner(test_flower)\n",
    "\n",
    "print(f\"\\nLogistic Regression Prediction:\")\n",
    "print(f\"Flower features: {test_flower}\")\n",
    "print(f\"Probability of being 'versicolor': {probability:.4f}\")\n",
    "print(f\"Probability of being 'setosa': {1-probability:.4f}\")\n",
    "print(f\"Predicted class: {'versicolor' if probability > 0.5 else 'setosa'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. MODEL EVALUATION & COMPARISON\n",
    "\n",
    "### 9.1. Why Do We Need Model Evaluation?\n",
    "\n",
    "So far we've looked at individual algorithms, but how do we know which one is best for our problem? We need systematic ways to:\n",
    "\n",
    "1. Measure performance: How accurate are our predictions?\n",
    "2. Compare algorithms: Which algorithm works better for this specific dataset?\n",
    "3. Avoid overfitting: Make sure our model works on new, unseen data\n",
    "\n",
    "### 9.2. Train-Test Split\n",
    "\n",
    "The most fundamental concept in machine learning evaluation is never test on the same data you trained on Think of it like this:\n",
    "\n",
    "- Training data: Like study materials for an exam\n",
    "- Test data: Like the actual exam questions (should be unseen!)\n",
    "\n",
    "If you memorize the answers to practice questions, that doesn't mean you understand the subject. Similarly, if a model memorizes the training data, it might not work on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's implement a simple train-test split function\n",
    "def train_test_split(dataset, test_ratio=0.3):\n",
    "    \"\"\"\n",
    "    Split dataset into training and testing sets.\n",
    "    \n",
    "    Args:\n",
    "        dataset: DataSet object\n",
    "        test_ratio: Fraction of data to use for testing (default 0.3 = 30%)\n",
    "    \n",
    "    Returns:\n",
    "        train_data, test_data: Two DataSet objects\n",
    "    \"\"\"\n",
    "    import random\n",
    "    import copy\n",
    "    \n",
    "    # Make a copy of the dataset to avoid modifying the original\n",
    "    all_examples = copy.deepcopy(dataset.examples)\n",
    "    random.shuffle(all_examples)  # Randomize the order\n",
    "    \n",
    "    # Calculate split point\n",
    "    total_examples = len(all_examples)\n",
    "    test_size = int(total_examples * test_ratio)\n",
    "    \n",
    "    # Split the data\n",
    "    test_examples = all_examples[:test_size]\n",
    "    train_examples = all_examples[test_size:]\n",
    "    \n",
    "    # Create new DataSet objects\n",
    "    train_data = copy.deepcopy(dataset)\n",
    "    train_data.examples = train_examples\n",
    "    \n",
    "    test_data = copy.deepcopy(dataset)\n",
    "    test_data.examples = test_examples\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "# Example: Split the iris dataset\n",
    "iris_full = DataSet(name=\"iris\")\n",
    "train_data, test_data = train_test_split(iris_full, test_ratio=0.3)\n",
    "\n",
    "print(f\"Original dataset: {len(iris_full.examples)} examples\")\n",
    "print(f\"Training set: {len(train_data.examples)} examples (70%)\")\n",
    "print(f\"Test set: {len(test_data.examples)} examples (30%)\")\n",
    "print(f\"First training example: {train_data.examples[0]}\")\n",
    "print(f\"First test example: {test_data.examples[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3. Measuring Accuracy\n",
    "\n",
    "**Accuracy** is the simplest performance metric: what percentage of predictions were correct?\n",
    "\n",
    "$$\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(learner, test_data):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of a learner on test data.\n",
    "    \n",
    "    Args:\n",
    "        learner: Trained learning function\n",
    "        test_data: DataSet object with test examples\n",
    "        \n",
    "    Returns:\n",
    "        accuracy: Float between 0 and 1\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = len(test_data.examples)\n",
    "    \n",
    "    for example in test_data.examples:\n",
    "        # Get input features (exclude target)\n",
    "        features = [example[i] for i in test_data.inputs]\n",
    "        # Get true label\n",
    "        true_label = example[test_data.target]\n",
    "        # Get prediction\n",
    "        prediction = learner(features)\n",
    "        \n",
    "        # Check if correct\n",
    "        if prediction == true_label:\n",
    "            correct += 1\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Example usage: Let's test this function\n",
    "# First train a simple k-NN on the training data\n",
    "knn_learner = NearestNeighborLearner(train_data, k=3)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = calculate_accuracy(knn_learner, test_data)\n",
    "print(f\"k-NN (k=3) Accuracy on test set: {accuracy:.2%}\")\n",
    "print(f\"This means the model got {accuracy*100:.1f}% of predictions correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4. Algorithm Comparison\n",
    "\n",
    "Now let's compare all our algorithms on the same dataset to see which performs best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different algorithms on the iris dataset\n",
    "print(\"ALGORITHM COMPARISON ON IRIS DATASET\")\n",
    "\n",
    "# Prepare data\n",
    "iris_for_comparison = DataSet(name=\"iris\")\n",
    "train_set, test_set = train_test_split(iris_for_comparison, test_ratio=0.3)\n",
    "\n",
    "algorithms = {}\n",
    "accuracies = {}\n",
    "\n",
    "# 1. k-Nearest Neighbors (different k values)\n",
    "print(\"\\nk-Nearest Neighbors:\")\n",
    "for k in [1, 3, 5, 7]:\n",
    "    learner = NearestNeighborLearner(train_set, k=k)\n",
    "    accuracy = calculate_accuracy(learner, test_set)\n",
    "    algorithms[f\"k-NN (k={k})\"] = learner\n",
    "    accuracies[f\"k-NN (k={k})\"] = accuracy\n",
    "    print(f\"   k={k}: {accuracy:.2%}\")\n",
    "\n",
    "# 2. Decision Tree\n",
    "print(\"\\nDecision Tree:\")\n",
    "dt_learner = DecisionTreeLearner(train_set)\n",
    "dt_accuracy = calculate_accuracy(dt_learner, test_set)\n",
    "algorithms[\"Decision Tree\"] = dt_learner\n",
    "accuracies[\"Decision Tree\"] = dt_accuracy\n",
    "print(f\"   Accuracy: {dt_accuracy:.2%}\")\n",
    "\n",
    "# 3. Linear Learner (for numerical output)\n",
    "print(\"\\nLinear Learner:\")\n",
    "# Note: Linear learner works better with numerical classes\n",
    "train_set_numeric = DataSet(name=\"iris\")\n",
    "train_set_numeric.examples = train_set.examples[:]\n",
    "train_set_numeric.classes_to_numbers()\n",
    "\n",
    "test_set_numeric = DataSet(name=\"iris\") \n",
    "test_set_numeric.examples = test_set.examples[:]\n",
    "test_set_numeric.classes_to_numbers()\n",
    "\n",
    "linear_learner = LinearLearner(train_set_numeric)\n",
    "\n",
    "# For classification, we need to round the output to nearest integer\n",
    "def linear_classifier(features):\n",
    "    raw_output = linear_learner(features)\n",
    "    # Round to nearest integer and clip to valid range\n",
    "    return max(0, min(2, round(raw_output)))\n",
    "\n",
    "# Calculate accuracy manually since we need the special classifier function\n",
    "correct = 0\n",
    "for example in test_set_numeric.examples:\n",
    "    features = [example[i] for i in test_set_numeric.inputs]\n",
    "    true_label = example[test_set_numeric.target]\n",
    "    prediction = linear_classifier(features)\n",
    "    if prediction == true_label:\n",
    "        correct += 1\n",
    "\n",
    "linear_accuracy = correct / len(test_set_numeric.examples)\n",
    "algorithms[\"Linear Learner\"] = linear_classifier\n",
    "accuracies[\"Linear Learner\"] = linear_accuracy\n",
    "print(f\"   Accuracy: {linear_accuracy:.2%}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\nRESULTS SUMMARY:\")\n",
    "print(\"-\" * 30)\n",
    "sorted_results = sorted(accuracies.items(), key=lambda x: x[1], reverse=True)\n",
    "for i, (algorithm, accuracy) in enumerate(sorted_results, 1):\n",
    "    medal = \"First!\" if i == 1 else \"Second!\" if i == 2 else \"Third!\" if i == 3 else \"  \"\n",
    "    print(f\"{medal} {algorithm}: {accuracy:.2%}\")\n",
    "    \n",
    "best_algorithm = sorted_results[0][0]\n",
    "print(f\"\\nBest performing algorithm: {best_algorithm}\")\n",
    "print(f\"Remember: Results may vary with different random splits!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5. Cross-Validation: A More Robust Evaluation\n",
    "\n",
    "The train-test split we used above has a problem: the results depend on which examples randomly end up in the test set. Cross-validation solves this by testing multiple times with different splits.\n",
    "\n",
    "How k-fold cross-validation works:\n",
    "\n",
    "1. Split the data into k equal parts (folds)\n",
    "2. Train on k-1 folds, test on the remaining fold\n",
    "3. Repeat k times, each time using a different fold for testing\n",
    "4. Average the results\n",
    "\n",
    "Let's use the built-in cross-validation function from our learning module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation comparison\n",
    "print(\"CROSS-VALIDATION COMPARISON (5-fold)\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "iris_cv = DataSet(name=\"iris\")\n",
    "\n",
    "# Test different algorithms with cross-validation\n",
    "cv_results = {}\n",
    "\n",
    "# k-NN with different k values\n",
    "print(\"\\nk-Nearest Neighbors:\")\n",
    "for k in [1, 3, 5]:\n",
    "    def make_knn_learner(dataset):\n",
    "        return NearestNeighborLearner(dataset, k=k)\n",
    "    \n",
    "    error_rate, std_dev = cross_validation(make_knn_learner, iris_cv, k=5)\n",
    "    accuracy = 1 - error_rate  # Convert error rate to accuracy\n",
    "    cv_results[f\"k-NN (k={k})\"] = accuracy\n",
    "    print(f\"   k={k}: {accuracy:.3f} Â± {std_dev:.3f}\")\n",
    "\n",
    "# Decision Tree\n",
    "print(\"\\nDecision Tree:\")\n",
    "dt_error, dt_std = cross_validation(DecisionTreeLearner, iris_cv, k=5)\n",
    "dt_accuracy = 1 - dt_error  # Convert error rate to accuracy\n",
    "cv_results[\"Decision Tree\"] = dt_accuracy\n",
    "print(f\"   Accuracy: {dt_accuracy:.3f} Â± {dt_std:.3f}\")\n",
    "\n",
    "print(\"\\nCross-Validation Results Summary:\")\n",
    "print(\"-\" * 35)\n",
    "for algorithm, accuracy in sorted(cv_results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{algorithm}: {accuracy:.1%}\")\n",
    "\n",
    "print(f\"\\nCross-validation gives us more reliable estimates!\")\n",
    "print(f\"These results are averaged over 5 different train/test splits.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. HANDS-ON EXERCISES\n",
    "\n",
    "Now it's time to apply what you've learned! These exercises will help you understand the concepts better through practice.\n",
    "\n",
    "### Exercise 1: Exploring the Zoo Dataset\n",
    "\n",
    "The zoo dataset contains information about different animals and their characteristics. Let's explore it and build a classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Load and explore the zoo dataset\n",
    "zoo = DataSet(name=\"zoo\")\n",
    "\n",
    "print(\"ZOO DATASET EXPLORATION\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Number of animals: {len(zoo.examples)}\")\n",
    "print(f\"Number of features: {len(zoo.inputs)}\")\n",
    "print(f\"Animal types: {zoo.values[zoo.target]}\")\n",
    "\n",
    "print(f\"\\nFirst few animals:\")\n",
    "for i in range(3):\n",
    "    animal = zoo.examples[i]\n",
    "    features = [animal[j] for j in zoo.inputs]\n",
    "    animal_type = animal[zoo.target]\n",
    "    print(f\"  Animal {i+1}: features={features}, type='{animal_type}'\")\n",
    "\n",
    "print(f\"\\nFeature information:\")\n",
    "print(f\"Each animal has {len(zoo.inputs)} binary features (0 or 1)\")\n",
    "print(f\"These represent characteristics like 'has hair', 'has feathers', etc.\")\n",
    "\n",
    "# ðŸŽ¯ YOUR TASK: \n",
    "print(f\"\\nYOUR TASK:\")\n",
    "print(f\"1. Try different k values for k-NN on the zoo dataset\")\n",
    "print(f\"2. Which k value works best?\") \n",
    "print(f\"3. How does Decision Tree perform compared to k-NN?\")\n",
    "\n",
    "# Starter code for your experiments:\n",
    "print(f\"\\nSTARTER CODE:\")\n",
    "print(f\"# zoo_train, zoo_test = train_test_split(zoo, test_ratio=0.3)\")\n",
    "print(f\"# knn_zoo = NearestNeighborLearner(zoo_train, k=?)\")\n",
    "print(f\"# accuracy = calculate_accuracy(knn_zoo, zoo_test)\")\n",
    "print(f\"# print(f'Accuracy: {{accuracy:.2%}}')\")\n",
    "\n",
    "# Uncomment and modify the lines below to start your experiments:\n",
    "# zoo_train, zoo_test = train_test_split(zoo, test_ratio=0.3)\n",
    "# knn_zoo = NearestNeighborLearner(zoo_train, k=1)\n",
    "# accuracy = calculate_accuracy(knn_zoo, zoo_test)\n",
    "# print(f\"k-NN (k=1) accuracy on zoo: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Distance Function Impact\n",
    "\n",
    "Different distance functions can significantly affect k-NN performance. Let's explore this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Test different distance functions\n",
    "print(\"DISTANCE FUNCTION COMPARISON\")\n",
    "\n",
    "# Create some test points\n",
    "point1 = [1, 2, 3]\n",
    "point2 = [4, 5, 6]\n",
    "\n",
    "print(f\"Comparing distances between {point1} and {point2}:\")\n",
    "print(f\"Manhattan Distance: {manhattan_distance(point1, point2)}\")\n",
    "print(f\"Euclidean Distance: {euclidean_distance(point1, point2):.3f}\")\n",
    "print(f\"Hamming Distance: {hamming_distance(point1, point2)}\")\n",
    "\n",
    "# Test with iris dataset using different distance functions\n",
    "iris_test = DataSet(name=\"iris\")\n",
    "\n",
    "# Create a k-NN learner with hamming distance\n",
    "iris_test.distance = hamming_distance\n",
    "knn_hamming = NearestNeighborLearner(iris_test, k=3)\n",
    "\n",
    "# Test the same flower as before\n",
    "test_prediction = knn_hamming([5.1, 3.0, 1.1, 0.1])\n",
    "\n",
    "print(f\"\\nPrediction with Hamming distance: {test_prediction}\")\n",
    "\n",
    "print(f\"\\nYOUR TASK:\")\n",
    "print(f\"1. Create different datasets with different distance functions\")\n",
    "print(f\"2. Compare their performance using cross-validation\")\n",
    "print(f\"3. Which distance function works best for the iris dataset?\")\n",
    "\n",
    "# Try this:\n",
    "# iris_euclidean = DataSet(name=\\\"iris\\\")\n",
    "# iris_euclidean.distance = euclidean_distance\n",
    "# knn_euclidean = NearestNeighborLearner(iris_euclidean, k=3)\n",
    "# accuracy_euclidean = cross_validation(lambda d: NearestNeighborLearner(d, k=3), iris_euclidean, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Create Your Own Classifier\n",
    "\n",
    "Now it's time to put everything together! Your challenge is to build the best possible classifier for a dataset of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Build your best classifier\n",
    "print(\"CLASSIFIER CHALLENGE\")\n",
    "\n",
    "print(\"YOUR MISSION:\")\n",
    "print(\"Build the best possible classifier for the dataset of your choice!\")\n",
    "print()\n",
    "print(\"REQUIREMENTS:\")\n",
    "print(\"1. Choose a dataset (iris, zoo, or restaurant)\")\n",
    "print(\"2. Try at least 3 different algorithms\")\n",
    "print(\"3. Experiment with different parameters (k values, distance functions)\")\n",
    "print(\"4. Use cross-validation to evaluate performance\")\n",
    "print(\"5. Report your best result!\")\n",
    "\n",
    "print(\"\\nMETHODOLOGY:\")\n",
    "print(\"1. Split your data or use cross-validation\")\n",
    "print(\"2. Try multiple algorithms:\")\n",
    "print(\"   - k-NN with different k values\")\n",
    "print(\"   - Decision Tree\")\n",
    "print(\"   - Linear/Logistic Learner (if appropriate)\")\n",
    "print(\"3. Compare results and pick the best\")\n",
    "\n",
    "print(\"\\nTEMPLATE CODE:\")\n",
    "print(\"\"\"\n",
    "# Step 1: Choose your dataset\n",
    "my_dataset = DataSet(name=\"???\")  # Fill in: iris, zoo, or restaurant\n",
    "\n",
    "# Step 2: Create comparison function\n",
    "def compare_algorithms(dataset):\n",
    "    results = {}\n",
    "    \n",
    "    # Try k-NN with different k values\n",
    "    for k in [1, 3, 5, 7]:\n",
    "        accuracy = cross_validation(lambda d: NearestNeighborLearner(d, k=k), dataset, k=5)\n",
    "        results[f'k-NN (k={k})'] = accuracy\n",
    "    \n",
    "    # Try Decision Tree\n",
    "    dt_accuracy = cross_validation(DecisionTreeLearner, dataset, k=5)\n",
    "    results['Decision Tree'] = dt_accuracy\n",
    "    \n",
    "    # Add more algorithms here!\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Step 3: Run comparison\n",
    "# results = compare_algorithms(my_dataset)\n",
    "\n",
    "# Step 4: Find the best\n",
    "# best_algorithm = max(results.items(), key=lambda x: x[1])\n",
    "# print(f\"Best algorithm: {best_algorithm[0]} with {best_algorithm[1]:.2%} accuracy\")\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nBONUS CHALLENGES:\")\n",
    "print(\"- Try different distance functions for k-NN\")\n",
    "print(\"- Create an ensemble (combine multiple algorithms)\")\n",
    "print(\"- Analyze which features are most important\")\n",
    "print(\"- Visualize your results\")\n",
    "\n",
    "print(\"\\nStart coding below this cell!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. SUMMARY & KEY TAKEAWAYS\n",
    "\n",
    "You've explored the fundamental concepts of machine learning. \n",
    "\n",
    "### Algorithms Covered\n",
    "1. k-Nearest Neighbors (k-NN): Simple, intuitive, works well with small datasets\n",
    "2. Decision Trees: Easy to interpret, automatically finds important features\n",
    "3. Linear Learner: Fast, works well for linearly separable data\n",
    "4. Logistic Linear Learner: Like linear learner but outputs probabilities\n",
    "\n",
    "### Key Insights\n",
    "- No single algorithm is always best - performance depends on the dataset\n",
    "- Evaluation is crucial - always test on unseen data\n",
    "- Parameters matter - choosing the right k, distance function, etc. affects performance\n",
    "- Cross-validation gives more reliable estimates than a single train-test split\n",
    "\n",
    "### When to Use Which Algorithm\n",
    "\n",
    "| Algorithm | Best For | Pros | Cons |\n",
    "|-----------|----------|------|------|\n",
    "| k-NN | Small datasets, complex boundaries | Simple, no training needed | Slow for large data, sensitive to irrelevant features |\n",
    "| Decision Tree | Interpretable models, mixed data types | Easy to understand, handles categorical data | Can overfit, unstable |\n",
    "| Linear Learner | Large datasets, simple relationships | Fast, stable | Only works for linear relationships |\n",
    "| Logistic Learner | Binary classification, probability outputs | Outputs probabilities, regularizable | Limited to linear boundaries |\n",
    "\n",
    "### Next Steps\n",
    "- Try these algorithms on your own datasets\n",
    "- Learn about more advanced techniques (neural networks, ensemble methods)\n",
    "- Explore feature engineering and data preprocessing\n",
    "- Study more evaluation metrics (precision, recall, F1-score)\n",
    "\n",
    "### Remember\n",
    "> \"The goal is not to find the perfect algorithm, but to find the algorithm that works best for your specific problem and data.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT CELL - Try your own ideas here!\n",
    "print(\"EXPERIMENT ZONE\")\n",
    "print(\"Use this cell to try your own experiments!\")\n",
    "print()\n",
    "print(\"Some ideas to get you started:\")\n",
    "print(\"- Test different datasets\")\n",
    "print(\"- Try unusual k values for k-NN\")  \n",
    "print(\"- Compare training vs test accuracy\")\n",
    "print(\"- Create visualizations of your results\")\n",
    "print()\n",
    "print(\"Remember: The best way to learn is by doing!\")\n",
    "\n",
    "# Your experimentation code goes here:\n",
    "# Example: Quick comparison of iris vs zoo performance\n",
    "#\n",
    "# print(\"Quick comparison:\")\n",
    "# iris_acc = cross_validation(lambda d: NearestNeighborLearner(d, k=3), DataSet(name=\"iris\"), k=5)\n",
    "# zoo_acc = cross_validation(lambda d: NearestNeighborLearner(d, k=3), DataSet(name=\"zoo\"), k=5)\n",
    "# print(f\"k-NN on Iris: {iris_acc:.2%}\")\n",
    "# print(f\"k-NN on Zoo: {zoo_acc:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
